services:
  transcriber:
    build: .
    container_name: zastupitelstvo_transcriber
    volumes:
      - ../input:/app/input:ro       # Mount input directory (read-only)
      - ../output:/app/output         # Mount output directory (read-write)
      - hf-cache:/root/.cache/huggingface  # Cache HuggingFace models
    environment:
      # HuggingFace token for downloading models (required)
      - HF_TOKEN=${HF_TOKEN}

      # Whisper model size: tiny, base, small, medium, large-v2, large-v3
      - WHISPER_MODEL=medium

      # Threading configuration for CPU performance
      - OMP_NUM_THREADS=12
      - MKL_NUM_THREADS=12
      - TORCH_NUM_THREADS=12

    # Command uses new argument-based interface
    # Adjust input/output paths as needed
    command: >
      python transcribe.py
      --audio /app/input/22_zasedani_Zastupitelstva_mesta_Litovel.opus
      --output /app/output/prepis.txt
      --model medium
      --device cpu
      --compute-type int8

volumes:
  hf-cache:
    # Persistent volume for caching downloaded models
    # Prevents re-downloading on container restart
